{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8832825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "from Court_detection import CourtDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0778e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Optional if you are using a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4502e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load moveNet model\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/multipose/lightning/1\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbee37",
   "metadata": {},
   "source": [
    "COURT DETECTOR MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7039904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPoseEstimation:\n",
    "\n",
    "    \"\"\"\n",
    "    Detecting and tracking player's position and skeleton\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,nb,type,movenet):\n",
    "\n",
    "        self.edges = {\n",
    "            (0, 1): 'm',\n",
    "            (0, 2): 'c',\n",
    "            (1, 3): 'm',\n",
    "            (2, 4): 'c',\n",
    "            (0, 5): 'm',\n",
    "            (0, 6): 'c',\n",
    "            (5, 7): 'm',\n",
    "            (7, 9): 'm',\n",
    "            (6, 8): 'c',\n",
    "            (8, 10): 'c',\n",
    "            (5, 6): 'y',\n",
    "            (5, 11): 'm',\n",
    "            (6, 12): 'c',\n",
    "            (11, 12): 'y',\n",
    "            (11, 13): 'm',\n",
    "            (13, 15): 'm',\n",
    "            (12, 14): 'c',\n",
    "            (14, 16): 'c'\n",
    "                    }\n",
    "        self.movenet= movenet\n",
    "        self.confidence_threshold = 0.1\n",
    "        #number of players must between 2-4\n",
    "        self.number_players = nb\n",
    "        #type of tracking : skeleton / bounding_box\n",
    "        self.type = type\n",
    "        self.skeletons =  []\n",
    "        self.positions =  []\n",
    "        self.center = 0\n",
    "\n",
    "\n",
    "    @jit\n",
    "    def draw_keypoints(self,frame, keypoints):\n",
    "        green = False\n",
    "        y, x, c = frame.shape\n",
    "        shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "        #self.skeletons.append(shaped)\n",
    "        for kp in shaped:\n",
    "            ky, kx, kp_conf = kp\n",
    "            if kp_conf > self.confidence_threshold:\n",
    "                cv2.circle(frame, (int(kx), int(ky)), 3, (0,255,0), -1)\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if(kp_conf > self.confidence_threshold):\n",
    "            self.skeletons.append(shaped)\n",
    "            green = True\n",
    "            return green\n",
    "\n",
    "    @jit\n",
    "    def draw_connections(self,frame, keypoints):\n",
    "    \n",
    "        y, x, c = frame.shape\n",
    "        shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "        for edge, color in self.edges.items():\n",
    "            p1, p2 = edge\n",
    "            y1, x1, c1 = shaped[p1]\n",
    "            y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "            if (c1 > self.confidence_threshold) & (c2 > self.confidence_threshold):      \n",
    "                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 3)\n",
    "\n",
    "    @jit\n",
    "    def find_player(self,center,centers,players):\n",
    "\n",
    "        A=np.array(list(centers.values()))\n",
    "        true_centers={}\n",
    "        true_players={}\n",
    "        for i in range(self.number_players):\n",
    "            distances = np.linalg.norm(A-np.array(center), axis=1)\n",
    "            key = list(centers.keys())[list(centers.values()).index(tuple(A[np.argmin(distances),:]))]\n",
    "            true_centers[key]=(int(A[np.argmin(distances),0]),int(A[np.argmin(distances),1]))\n",
    "            true_players[key]=players[key]\n",
    "            A = np.delete(A,np.argmin(distances),0)\n",
    "            players.pop(key)\n",
    "\n",
    "        return true_centers,true_players\n",
    "\n",
    "    @jit\n",
    "    def detect_player(self,input_img,frame,court):\n",
    "\n",
    "        results = self.movenet(input_img)\n",
    "\n",
    "        centers={}\n",
    "        players={}\n",
    "\n",
    "        for i in range(6):\n",
    "\n",
    "            ymin,xmin,ymax,xmax = np.squeeze(results['output_0'][:,:,51:])[i][:4]\n",
    "\n",
    "            start_point=tuple(np.multiply(np.array([xmin,ymin]), [frame.shape[1],frame.shape[0]]).astype(int))\n",
    "            end_point=tuple(np.multiply(np.array([xmax,ymax]), [frame.shape[1],frame.shape[0]]).astype(int))\n",
    "\n",
    "            #position circle on zones to be checked after if here is player or not\n",
    "            center = (int((start_point[0]+end_point[0])/2), int(end_point[1])) #center of player (x,y)\n",
    "            centers[i]=center\n",
    "            players[i]=(start_point,end_point)\n",
    "        \n",
    "\n",
    "        if court is not None:\n",
    "        \n",
    "            #range is same passed to find_player\n",
    "            centers,players = self.find_player(court[1],centers,players)\n",
    "            for key,value in centers.items():\n",
    "            \n",
    "                if cv2.pointPolygonTest(court[0],value,False) == 1.0: #1 inside contour / 0 on the edge\n",
    "\n",
    "                    if(self.type=='bounding_box'):\n",
    "                        #bounding box\n",
    "                        cv2.rectangle(frame,players[key][0],players[key][1],( 255 , 0 , 0 ),3)\n",
    "                        cv2.putText(frame,\"Player\", (players[key][0][0],players[key][0][1]), cv2.FONT_HERSHEY_TRIPLEX, 1.0, (0, 255, 0))\n",
    "\n",
    "                    if(self.type=='skeleton'):\n",
    "                        #Render keypoints\n",
    "                        person = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))[key]\n",
    "                        self.draw_connections(frame, person)\n",
    "                        green = self.draw_keypoints(frame, person)\n",
    "                        if(green):\n",
    "                            self.positions.append(value)\n",
    "                            cv2.circle(frame,value,8,( 0 , 255 , 0 ),-1)\n",
    "                            cv2.putText(frame,\"Player\", (players[key][0][0],players[key][0][1]), cv2.FONT_HERSHEY_TRIPLEX, 1.0, (0 , 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e443c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jit\n",
    "def test(court_model,multipose):\n",
    "\n",
    "    #if webcome : change to 0\n",
    "    cap = cv2.VideoCapture('./TrackNetv2/profession_dataset/profession_dataset/match19/rally_video/1_01_01.mp4')\n",
    "    ret, frame = cap.read()\n",
    "    court = court_model.detect_court(frame)\n",
    "    #looping through all frames of the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "        multipose.detect_player(input_img,frame,court)\n",
    "            \n",
    "        multipose.positions=[]\n",
    "        multipose.skeletons=[]\n",
    "        frame = cv2.resize(frame,[1000,700])\n",
    "        cv2.imshow('Player Detection', frame)\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5956165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\2981697338.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"test\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\2981697338.py (5)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\2981697338.py\", line 5:\u001b[0m\n",
      "\u001b[1mdef test(court_model,multipose):\n",
      "    <source elided>\n",
      "    #if webcome : change to 0\n",
      "\u001b[1m    cap = cv2.VideoCapture('./TrackNetv2/profession_dataset/profession_dataset/match19/rally_video/1_01_01.mp4')\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "d:\\python\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"test\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\2981697338.py\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef test(court_model,multipose):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "d:\\python\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\2981697338.py\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef test(court_model,multipose):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py:88: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"detect_player\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py (91)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py\", line 91:\u001b[0m\n",
      "\u001b[1m    def detect_player(self,input_img,frame,court):\n",
      "        <source elided>\n",
      "\n",
      "\u001b[1m        results = self.movenet(input_img)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py:88: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"detect_player\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py\", line 112:\u001b[0m\n",
      "\u001b[1m    def detect_player(self,input_img,frame,court):\n",
      "        <source elided>\n",
      "            #range is same passed to find_player\n",
      "\u001b[1m            centers,players = self.find_player(court[1],centers,players)\n",
      "\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "d:\\python\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"detect_player\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py\", line 91:\u001b[0m\n",
      "\u001b[1m    def detect_player(self,input_img,frame,court):\n",
      "        <source elided>\n",
      "\n",
      "\u001b[1m        results = self.movenet(input_img)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "d:\\python\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\jouin\\AppData\\Local\\Temp\\ipykernel_11124\\160183022.py\", line 91:\u001b[0m\n",
      "\u001b[1m    def detect_player(self,input_img,frame,court):\n",
      "        <source elided>\n",
      "\n",
      "\u001b[1m        results = self.movenet(input_img)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "multipose = MultiPoseEstimation(2,'skeleton',movenet)\n",
    "court_model = CourtDetector()\n",
    "test(court_model,multipose)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
